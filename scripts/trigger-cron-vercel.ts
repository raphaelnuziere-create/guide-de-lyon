// Script pour dÃ©clencher le cron job sur Vercel
import { createClient } from '@supabase/supabase-js';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!;
const supabase = createClient(supabaseUrl, supabaseKey);

async function triggerCronJob() {
  console.log('ğŸš€ DÃ©clenchement du cron job de scraping sur Vercel\n');
  console.log('=' .repeat(60));
  
  // URL de production
  const productionUrl = 'https://guide-de-lyon.vercel.app';
  const cronSecret = process.env.CRON_SECRET || 'your-cron-secret-here';
  
  try {
    // 1. VÃ©rifier d'abord que les sources sont bien configurÃ©es
    console.log('ğŸ“‹ VÃ©rification des sources...');
    const { data: sources, error: sourcesError } = await supabase
      .from('scraping_sources')
      .select('*')
      .eq('is_active', true);
    
    if (sourcesError || !sources || sources.length === 0) {
      console.error('âŒ Aucune source active trouvÃ©e dans la base de donnÃ©es');
      console.log('ExÃ©cutez d\'abord le SQL: 20250108_insert_sources_fixed.sql');
      return;
    }
    
    console.log(`âœ… ${sources.length} sources actives trouvÃ©es:`);
    sources.forEach(s => console.log(`   - ${s.name} (${s.type})`));
    
    // 2. DÃ©clencher le cron job
    console.log(`\nğŸ“¡ Appel du cron: ${productionUrl}/api/cron/scraping`);
    console.log('â³ Scraping en cours (30-60 secondes)...\n');
    
    const response = await fetch(`${productionUrl}/api/cron/scraping`, {
      method: 'GET',
      headers: {
        'x-cron-secret': cronSecret,
        'User-Agent': 'Mozilla/5.0 (compatible; Vercel-Cron/1.0)'
      }
    });
    
    const responseText = await response.text();
    let data;
    
    try {
      data = JSON.parse(responseText);
    } catch {
      data = { message: responseText };
    }
    
    if (response.ok) {
      console.log('âœ… Cron exÃ©cutÃ© avec succÃ¨s!');
      
      if (data.summary) {
        console.log('\nğŸ“Š RÃ©sumÃ© du scraping:');
        console.log('-'.repeat(40));
        console.log(`Articles scrapÃ©s: ${data.summary.totalScraped}`);
        console.log(`Articles rÃ©Ã©crits: ${data.summary.totalRewritten}`);
        console.log(`Articles publiÃ©s: ${data.summary.totalPublished}`);
        
        if (data.summary.sources) {
          console.log('\nDÃ©tail par source:');
          data.summary.sources.forEach((s: any) => {
            console.log(`  ${s.source}: ${s.scraped} articles`);
          });
        }
      }
      
      // 3. VÃ©rifier les articles dans la base
      console.log('\nğŸ” VÃ©rification des articles dans la base...');
      await new Promise(resolve => setTimeout(resolve, 2000)); // Attendre 2s
      
      const { data: articles, error: articlesError } = await supabase
        .from('scraped_articles')
        .select('rewritten_title, status, author_name, published_at')
        .order('created_at', { ascending: false })
        .limit(5);
      
      if (!articlesError && articles && articles.length > 0) {
        console.log(`\nâœ… ${articles.length} derniers articles:`);
        articles.forEach(a => {
          const status = a.status === 'published' ? 'âœ…' : 'â³';
          console.log(`  ${status} ${a.rewritten_title || 'En cours de traitement...'}`);
          if (a.author_name) console.log(`     Auteur: ${a.author_name}`);
        });
      } else {
        console.log('â³ Pas encore d\'articles (le traitement peut prendre du temps)');
      }
      
    } else {
      console.error(`âŒ Erreur cron: ${response.status}`);
      console.error('RÃ©ponse:', data);
      
      if (response.status === 401) {
        console.log('\nâš ï¸  Erreur d\'authentification CRON_SECRET');
        console.log('VÃ©rifiez que CRON_SECRET est configurÃ© sur Vercel');
      } else if (response.status === 404) {
        console.log('\nâš ï¸  Route non trouvÃ©e. Le dÃ©ploiement est peut-Ãªtre en cours.');
      }
    }
    
  } catch (error) {
    console.error('âŒ Erreur:', error);
  }
  
  console.log('\n' + '='.repeat(60));
  console.log('ğŸ”— Liens pour vÃ©rifier les rÃ©sultats:');
  console.log(`ğŸ“° Page actualitÃ©s: ${productionUrl}/actualites`);
  console.log(`ğŸ“° Route Lyon: ${productionUrl}/actualites/lyon`);
  console.log('ğŸ“Š Dashboard Supabase: https://supabase.com/dashboard');
  console.log('\nğŸ’¡ Note: Les articles peuvent prendre quelques minutes pour apparaÃ®tre');
  console.log('   car ils sont rÃ©Ã©crits avec l\'IA avant publication.');
}

// Alternative: dÃ©clencher directement l'API de scraping manuel
async function triggerManualScraping() {
  console.log('\nğŸ”„ Alternative: DÃ©clenchement du scraping manuel...\n');
  
  try {
    const response = await fetch('https://guide-de-lyon.vercel.app/api/scraping/manual-trigger', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      }
    });
    
    if (response.ok) {
      const data = await response.json();
      console.log('âœ… Scraping manuel rÃ©ussi');
      console.log('RÃ©sumÃ©:', data.message);
    } else {
      console.log('âŒ Ã‰chec du scraping manuel');
    }
  } catch (error) {
    console.log('âŒ Erreur scraping manuel:', error);
  }
}

// ExÃ©cuter les tests
async function main() {
  await triggerCronJob();
  
  // Si le cron Ã©choue, essayer le scraping manuel
  const { data: articles } = await supabase
    .from('scraped_articles')
    .select('id')
    .limit(1);
  
  if (!articles || articles.length === 0) {
    console.log('\nâš ï¸  Aucun article trouvÃ©, tentative de scraping manuel...');
    await triggerManualScraping();
  }
  
  console.log('\nâœ¨ Test terminÃ©');
}

main()
  .then(() => process.exit(0))
  .catch((error) => {
    console.error('âŒ Erreur fatale:', error);
    process.exit(1);
  });